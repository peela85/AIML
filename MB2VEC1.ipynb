{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MB2VEC1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gGDY44vTUS9r","colab_type":"text"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n"]},{"cell_type":"markdown","metadata":{"id":"KPOdKTG0US9t","colab_type":"text"},"source":["The objective of this experiment is to understand word2vec, by seeing it in action."]},{"cell_type":"markdown","metadata":{"id":"GDTJ3UXdUS9v","colab_type":"text"},"source":["In this experiment we will use **Mahabharata** as our text corpus"]},{"cell_type":"markdown","metadata":{"id":"q5bGBzVwUS9w","colab_type":"text"},"source":["#### Keywords\n","\n","* Word2Vec\n","* Representation\n","* Stemming\n"]},{"cell_type":"markdown","metadata":{"id":"3Renbl5wUS97","colab_type":"text"},"source":["The problem with count-based representations is that \n","\n","1.  they are costly in terms of memory\n","\n","2. they discard all context and meaning ofwords\n","\n","\n","A better way to do this is by using a representation called \"Word2Vec\" with transforms each word into 300-dimensional vectors."]},{"cell_type":"markdown","metadata":{"id":"kHzaY69a--Uk","colab_type":"text"},"source":["#### Setup Steps"]},{"cell_type":"code","metadata":{"id":"xCsz-5gK-8Tl","colab_type":"code","colab":{}},"source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P181902225\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj3G7OzX_IvQ","colab_type":"code","colab":{}},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"9059040698\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ko4z17mBvzM","colab_type":"code","cellView":"form","outputId":"bc7f0fe3-1ef8-4bb6-e6ed-193c73cdd705","executionInfo":{"status":"ok","timestamp":1557030073556,"user_tz":-330,"elapsed":15730,"user":{"displayName":"pavan pradeep peela","photoUrl":"","userId":"06985232101628874739"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"M1_DL_MB2VEC1\" #name of the notebook\n","Answer = \"This notebook is not graded\"\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/MB.txt\")\n","  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/MB2Vec.bin\")\n","  \n","  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/stopwords.txt\")\n"," \n","  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/word2vec.png\")\n"," \n","  ipython.magic(\"sx pip3 install gensim\")\n","  print (\"Setup completed successfully\")\n","  return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      print(\"Your submission is successful.\")\n","      print(\"Ref Id:\", submission_id)\n","      print(\"Date of submission: \", r[\"date\"])\n","      print(\"Time of submission: \", r[\"time\"])\n","      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n","      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l72Cp7USUS98","colab_type":"text"},"source":["#### Importing the required packages"]},{"cell_type":"code","metadata":{"id":"PJUrWMcNUS9-","colab_type":"code","colab":{}},"source":["#vector space modeling and topic modeling toolkit\n","import gensim\n","\n","# Operating System\n","import os\n","\n","# Regular Expression\n","import re\n","\n","# nltk packages\n","from nltk.stem.snowball import SnowballStemmer\n","\n","# Basic Packages\n","import numpy as np\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI9RkeXzUS-C","colab_type":"text"},"source":["**Snowball** is a small string processing language designed for creating stemming algorithms for use in Information Retrieval. "]},{"cell_type":"markdown","metadata":{"id":"D_GfauhuUS-D","colab_type":"text"},"source":["#### Creating a new instance of a language specific subclass."]},{"cell_type":"code","metadata":{"id":"hb3haIdJUS-E","colab_type":"code","colab":{}},"source":["stemmer = SnowballStemmer(\"english\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vsQRpmkIUS-I","colab_type":"text"},"source":["### Preprocessing\n","\n","1. Cleaning dataset for text encoding issues :- Very useful when dealing with non-unicode characters. Most often when you read files prepared on Windows, in a Linux/Unix machine\n","2. Creating a set of vocabulary excluding the stopwords\n","3. Stemming a word.\n","    \n","        Eg: print(stemmer.stem(\"running\"))\n","    \n","        run"]},{"cell_type":"code","metadata":{"id":"lTPQhdT3gLq4","colab_type":"code","colab":{}},"source":["stopWords = pd.read_csv('stopwords.txt').values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBaRsHK0gJWN","colab_type":"code","colab":{}},"source":["class Load_Data(object):\n","    def __init__(self, fnamelist):\n","        self.fnamelist = fnamelist\n","        # Creating a set of vocabulary\n","        self.vocabulary = set([])\n","\n","    def __iter__(self):\n","        for fname in self.fnamelist:\n","            for line in open(fname, encoding='latin1'):\n","                words = re.findall(r'(\\b[a-z][a-z]*\\b)', line.lower())\n","                words = [word for word in words if not word in stopWords]\n","                for word in words:\n","                    self.vocabulary.add(word)\n","                yield words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qL6Wat1hgPlW","colab_type":"code","colab":{}},"source":["MB_txt = Load_Data(['MB.txt'])\n","model = gensim.models.Word2Vec(MB_txt, min_count=100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9GwHJw19gR50","colab_type":"code","colab":{}},"source":["model.save(\"MB2Vec_Without_stemmer.bin\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxUtZNYZ7Ovb","colab_type":"code","colab":{}},"source":["krishna5_without_stemmer = model.wv.most_similar('krishna')[:5]\n","\n","for name, similarity in krishna5_without_stemmer:\n","    print(\"Name: {} similarity: {}\".format(name, round(similarity,2)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xERgMkdVUS-J","colab_type":"code","colab":{}},"source":["class Load_Data_stemmed(object):\n","    def __init__(self, fnamelist):\n","        self.fnamelist = fnamelist\n","        # Creating a set of vocabulary\n","        self.vocabulary = set([])\n","\n","    def __iter__(self):\n","        for fname in self.fnamelist:\n","            for line in open(fname, encoding='latin1'):\n","                words = re.findall(r'(\\b[a-z][a-z]*\\b)', line.lower())\n","                # Stemming a word.\n","                words = [ stemmer.stem(word) for word in words if not word in stopWords]\n","                for word in words:\n","                    self.vocabulary.add(word)\n","                yield words"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XtdzGuOHUS-O","colab_type":"text"},"source":["Now, Let us read the data using an iterator in the class defined above, which is a memory-friendly iterator. Save the pretrained vectors using Gensim"]},{"cell_type":"code","metadata":{"id":"vp9vy2jqUS-Q","colab_type":"code","colab":{}},"source":["MB_txt_stemmed = Load_Data_stemmed(['MB.txt'])\n","model = gensim.models.Word2Vec(MB_txt_stemmed, min_count=100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRh2HKenevQl","colab_type":"code","colab":{}},"source":["model.save(\"MB2Vec_With_stemmer.bin\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qsLVCmquUS-W","colab_type":"text"},"source":["Now Let us see what are the similar words related to certain characters names."]},{"cell_type":"code","metadata":{"id":"gqx5BtMhUS-X","colab_type":"code","colab":{}},"source":["krishna5_with_stemmer =  model.wv.most_similar('krishna')[:5]\n","for name, similarity in krishna5_with_stemmer:\n","  print(\"Name: {} similarity: {}\".format(name, round(similarity,2)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jNXPPrGUACLC","colab_type":"text"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"R-Lp-yyGAFgV","colab_type":"code","colab":{}},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTIMBEbcAImT","colab_type":"code","colab":{}},"source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t46M3oOXALHu","colab_type":"code","colab":{}},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y09mkp86ALSb","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Run this cell to submit your notebook { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fTB7RbxE6c0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
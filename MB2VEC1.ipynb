{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MB2VEC1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peela85/AIML/blob/master/MB2VEC1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGDY44vTUS9r",
        "colab_type": "text"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPOdKTG0US9t",
        "colab_type": "text"
      },
      "source": [
        "The objective of this experiment is to understand word2vec, by seeing it in action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDTJ3UXdUS9v",
        "colab_type": "text"
      },
      "source": [
        "In this experiment we will use **Mahabharata** as our text corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5bGBzVwUS9w",
        "colab_type": "text"
      },
      "source": [
        "#### Keywords\n",
        "\n",
        "* Word2Vec\n",
        "* Representation\n",
        "* Stemming\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Renbl5wUS97",
        "colab_type": "text"
      },
      "source": [
        "The problem with count-based representations is that \n",
        "\n",
        "1.  they are costly in terms of memory\n",
        "\n",
        "2. they discard all context and meaning ofwords\n",
        "\n",
        "\n",
        "A better way to do this is by using a representation called \"Word2Vec\" with transforms each word into 300-dimensional vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHzaY69a--Uk",
        "colab_type": "text"
      },
      "source": [
        "#### Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCsz-5gK-8Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"P181902225\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj3G7OzX_IvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9059040698\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ko4z17mBvzM",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "bc7f0fe3-1ef8-4bb6-e6ed-193c73cdd705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook=\"M1_DL_MB2VEC1\" #name of the notebook\n",
        "Answer = \"This notebook is not graded\"\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/MB.txt\")\n",
        "  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/MB2Vec.bin\")\n",
        "  \n",
        "  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/stopwords.txt\")\n",
        " \n",
        "  ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/word2vec.png\")\n",
        " \n",
        "  ipython.magic(\"sx pip3 install gensim\")\n",
        "  print (\"Setup completed successfully\")\n",
        "  return\n",
        "\n",
        "def submit_notebook():\n",
        "    \n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      print(\"Your submission is successful.\")\n",
        "      print(\"Ref Id:\", submission_id)\n",
        "      print(\"Date of submission: \", r[\"date\"])\n",
        "      print(\"Time of submission: \", r[\"time\"])\n",
        "      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n",
        "      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "      return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if Additional: return Additional      \n",
        "    else: raise NameError('')\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "  \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup completed successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l72Cp7USUS98",
        "colab_type": "text"
      },
      "source": [
        "#### Importing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJUrWMcNUS9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vector space modeling and topic modeling toolkit\n",
        "import gensim\n",
        "\n",
        "# Operating System\n",
        "import os\n",
        "\n",
        "# Regular Expression\n",
        "import re\n",
        "\n",
        "# nltk packages\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# Basic Packages\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI9RkeXzUS-C",
        "colab_type": "text"
      },
      "source": [
        "**Snowball** is a small string processing language designed for creating stemming algorithms for use in Information Retrieval. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_GfauhuUS-D",
        "colab_type": "text"
      },
      "source": [
        "#### Creating a new instance of a language specific subclass."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb3haIdJUS-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JZx-WjARRgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6485616b-27f7-4715-f833-1de9976ed933"
      },
      "source": [
        "print(stemmer.stem(\"running\"))\n",
        "print(stemmer.stem(\"run\"))\n",
        "print(stemmer.stem(\"runs\"))\n",
        "\n",
        "print(stemmer.stem(\"authorize\"))\n",
        "print(stemmer.stem(\"authorized\"))\n",
        "print(stemmer.stem(\"authority\"))\n",
        "print(stemmer.stem(\"authorization\"))\n",
        "print(stemmer.stem(\"authorixing\"))\n",
        "\n",
        "print(stemmer.stem(\"matrices\"))\n",
        "print(stemmer.stem(\"matrix\"))\n",
        "print(stemmer.stem(\"police\"))\n",
        "print(stemmer.stem(\"policy\"))\n",
        "print(stemmer.stem(\"european\"))\n",
        "print(stemmer.stem(\"europe\"))\n",
        "print(stemmer.stem(\"stocking\"))\n",
        "print(stemmer.stem(\"stocks\"))\n",
        "\n",
        "\n",
        "print(stemmer.stem(\"someone challenging\"))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run\n",
            "run\n",
            "run\n",
            "author\n",
            "author\n",
            "author\n",
            "author\n",
            "authorix\n",
            "matric\n",
            "matrix\n",
            "polic\n",
            "polici\n",
            "european\n",
            "europ\n",
            "stock\n",
            "stock\n",
            "someone challeng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsQRpmkIUS-I",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "1. Cleaning dataset for text encoding issues :- Very useful when dealing with non-unicode characters. Most often when you read files prepared on Windows, in a Linux/Unix machine\n",
        "2. Creating a set of vocabulary excluding the stopwords\n",
        "3. Stemming a word.\n",
        "    \n",
        "        Eg: print(stemmer.stem(\"running\"))\n",
        "    \n",
        "        run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTPQhdT3gLq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopWords = pd.read_csv('stopwords.txt').values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBaRsHK0gJWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Load_Data(object):\n",
        "    def __init__(self, fnamelist):\n",
        "        self.fnamelist = fnamelist\n",
        "        # Creating a set of vocabulary\n",
        "        self.vocabulary = set([])\n",
        "\n",
        "    def __iter__(self):\n",
        "        for fname in self.fnamelist:\n",
        "            for line in open(fname, encoding='latin1'):\n",
        "                words = re.findall(r'(\\b[a-z][a-z]*\\b)', line.lower())\n",
        "                words = [word for word in words if not word in stopWords]\n",
        "                for word in words:\n",
        "                    self.vocabulary.add(word)\n",
        "                yield words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL6Wat1hgPlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MB_txt = Load_Data(['MB.txt'])\n",
        "model = gensim.models.Word2Vec(MB_txt, min_count=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GwHJw19gR50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"MB2Vec_Without_stemmer.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrpFRGIxWtiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?gensim.models.word2vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV0XBPxyXbau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc3fa991-ba3d-45ac-ba4f-d24db5d95ac0"
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
        "\n",
        "print(cores)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxUtZNYZ7Ovb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "23753c5c-c69b-4376-f173-c93df50c3e10"
      },
      "source": [
        "krishna5_without_stemmer = model.wv.most_similar('krishna')[:5]\n",
        "\n",
        "for name, similarity in krishna5_without_stemmer:\n",
        "    print(\"Name: {} similarity: {}\".format(name, round(similarity,2)))\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: kesava similarity: 0.87\n",
            "Name: vasudeva similarity: 0.8\n",
            "Name: govinda similarity: 0.76\n",
            "Name: madhava similarity: 0.73\n",
            "Name: dhananjaya similarity: 0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7XP-qUHZjFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b128f37a-d50c-4467-88b8-78522de724aa"
      },
      "source": [
        "krishna5_without_stemmer = model.wv.most_similar('arjuna')[:10]\n",
        "\n",
        "for name, similarity in krishna5_without_stemmer:\n",
        "    print(\"Name: {} similarity: {}\".format(name, round(similarity,2)))\n",
        "    "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: partha similarity: 0.88\n",
            "Name: dhananjaya similarity: 0.84\n",
            "Name: kama similarity: 0.84\n",
            "Name: bhima similarity: 0.8\n",
            "Name: vrikodara similarity: 0.79\n",
            "Name: vibhatsu similarity: 0.78\n",
            "Name: abhimanyu similarity: 0.76\n",
            "Name: charioteer similarity: 0.76\n",
            "Name: satyaki similarity: 0.74\n",
            "Name: salya similarity: 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xERgMkdVUS-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Load_Data_stemmed(object):\n",
        "    def __init__(self, fnamelist):\n",
        "        self.fnamelist = fnamelist\n",
        "        # Creating a set of vocabulary\n",
        "        self.vocabulary = set([])\n",
        "\n",
        "    def __iter__(self):\n",
        "        for fname in self.fnamelist:\n",
        "            for line in open(fname, encoding='latin1'):\n",
        "                words = re.findall(r'(\\b[a-z][a-z]*\\b)', line.lower())\n",
        "                # Stemming a word.\n",
        "                words = [ stemmer.stem(word) for word in words if not word in stopWords]\n",
        "                for word in words:\n",
        "                    self.vocabulary.add(word)\n",
        "                yield words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtdzGuOHUS-O",
        "colab_type": "text"
      },
      "source": [
        "Now, Let us read the data using an iterator in the class defined above, which is a memory-friendly iterator. Save the pretrained vectors using Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp9vy2jqUS-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MB_txt_stemmed = Load_Data_stemmed(['MB.txt'])\n",
        "model = gensim.models.Word2Vec(MB_txt_stemmed, min_count=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRh2HKenevQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"MB2Vec_With_stemmer.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsLVCmquUS-W",
        "colab_type": "text"
      },
      "source": [
        "Now Let us see what are the similar words related to certain characters names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqx5BtMhUS-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4f2702f4-64c7-4a11-904a-078223b11ec5"
      },
      "source": [
        "krishna5_with_stemmer =  model.wv.most_similar('krishna')[:5]\n",
        "for name, similarity in krishna5_with_stemmer:\n",
        "  print(\"Name: {} similarity: {}\".format(name, round(similarity,2)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: kesava similarity: 0.84\n",
            "Name: madhava similarity: 0.78\n",
            "Name: vasudeva similarity: 0.76\n",
            "Name: govinda similarity: 0.76\n",
            "Name: arjuna similarity: 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNXPPrGUACLC",
        "colab_type": "text"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Lp-yyGAFgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTIMBEbcAImT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"Its a good one where he just went through line by line\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t46M3oOXALHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y09mkp86ALSb",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "34f8060d-9d52-4832-f4c9-8d7d3842f20a"
      },
      "source": [
        "#@title Run this cell to submit your notebook { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id =return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 9832\n",
            "Date of submission:  05 May 2019\n",
            "Time of submission:  10:47:37\n",
            "View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\n",
            "For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTB7RbxE6c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFoYb0Vu3xj2"
   },
   "source": [
    "# Advanced Certification in AIML\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kq7GFMbeOx9x"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eH4DRCIdYU-g"
   },
   "source": [
    "At the end of the experiment, you will be able to :\n",
    "\n",
    "* Reduce dimenssionality of the data using PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "tA32BgTAyM4U"
   },
   "outputs": [],
   "source": [
    "#@title Experiment Walkthrough\n",
    "#@markdown PCA for IRIS\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<video width='320' height='240' controls> <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/Week_1/pca.mp4\" type=\"video/mp4\"></video>\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VW7qEXuY6L3"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4iv6QMD0Y8Hc"
   },
   "source": [
    "#### History\n",
    "\n",
    "This is a multivariate dataset introduced by R.A.Fisher (Father of Modern Statistics) for showcasing linear discriminant analysis. This is arguably the best known dataset in Feature Selection literature.\n",
    "\n",
    "\n",
    "The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XA_1zVozYYWo"
   },
   "source": [
    "#### Description\n",
    "The Iris dataset consists of 150 data instances. There are 3 classes (Iris Versicolor, Iris Setosa and Iris Virginica) each have 50 instances. \n",
    "\n",
    "\n",
    "For each flower we have the below data attributes \n",
    "\n",
    "- sepal length in cm\n",
    "- sepal width in cm\n",
    "- petal length in cm\n",
    "- petal width in cm\n",
    "\n",
    "To make our experiment easy we rename the classes  with numbers : \n",
    "\n",
    "    \"0\": setosa\n",
    "    \"1\": versicolor\n",
    "    \"2\": virginica\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmrsv7oxZNN3"
   },
   "source": [
    "### Challenges\n",
    "\n",
    "When we use the data with large number of features or dimensionality, models usually choke because\n",
    "\n",
    "    1. Training time increases exponentially with number of features.\n",
    "    2. Models have increasing risk of overfitting with increasing number of features.\n",
    "    \n",
    "To avoid the above mentioned problems while learning about data analysis, we use simple, well behaved, data that reduces the cognitive load, and makes it easier to debug as we are able to better comprehend the data we are working with.  \n",
    "\n",
    "Hence, this is a good dataset to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n95mNFiNZRdp"
   },
   "source": [
    "### Domain Information\n",
    "\n",
    "Iris Plants are flowering plants with showy flowers. They are very popular among movie directors as it gives excellent background. \n",
    "\n",
    "They are predominantly found in dry, semi-desert, or colder rocky mountainous areas in Europe and Asia. They have long, erect flowering stems and can produce white, yellow, orange, pink, purple, lavender, blue or brown colored flowers. There are 260 to 300 types of iris.\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1275/1*7bnLKsChXq94QjtAiRn40w.png)\n",
    "\n",
    "As you could see, flowers have 3 sepals and 3 petals.  The sepals are usually spreading or drop downwards and the petals stand upright, partly behind the sepal bases. However, the length and width of the sepals and petals vary for each type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWQXDLCDOxjj"
   },
   "source": [
    "##AI/ML Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26edl0KhOxPy"
   },
   "source": [
    "In order to perform dimensionality reduction on Iris datase we use PCA\n",
    "\n",
    "**Principal Component Analysis (PCA)**\n",
    "\n",
    "PCA is linear algebra technique widely used for feature extraction and dimensionality reduction.\n",
    "PCA helps us identify hidden relationships, similarities or differences, then we can make dimension reduction. However, PCA is the best known and used to reduce the dimensions of dataset. Not only dimensionality reduction we can also perform data compression or feature extraction over the output of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyCkPh6n31J-"
   },
   "source": [
    "### Setup Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwEEgTFn3zXY"
   },
   "outputs": [],
   "source": [
    "#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n",
    "Id = \"\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nfSi0bRF4AJV"
   },
   "outputs": [],
   "source": [
    "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
    "password = \"\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "RSJlBdhm4EP_"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to complete the setup for this Notebook\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "  \n",
    "notebook=\"M1W1_004_PCA_Iris_C\" #name of the notebook\n",
    "\n",
    "def setup():\n",
    "#  ipython.magic(\"sx pip3 install torch\")  \n",
    "    from IPython.display import HTML, display\n",
    "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
    "    print(\"Setup completed successfully\")\n",
    "    return\n",
    "\n",
    "def submit_notebook():\n",
    "    \n",
    "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
    "    \n",
    "    import requests, json, base64, datetime\n",
    "\n",
    "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
    "    if not submission_id:\n",
    "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
    "      r = requests.post(url, data = data)\n",
    "      r = json.loads(r.text)\n",
    "\n",
    "      if r[\"status\"] == \"Success\":\n",
    "          return r[\"record_id\"]\n",
    "      elif \"err\" in r:        \n",
    "        print(r[\"err\"])\n",
    "        return None        \n",
    "      else:\n",
    "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
    "        return None\n",
    "\n",
    "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n",
    "      f = open(notebook + \".ipynb\", \"rb\")\n",
    "      file_hash = base64.b64encode(f.read())\n",
    "\n",
    "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
    "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
    "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
    "              \"notebook\" : notebook}\n",
    "\n",
    "      r = requests.post(url, data = data)\n",
    "      r = json.loads(r.text)\n",
    "      print(\"Your submission is successful.\")\n",
    "      print(\"Ref Id:\", submission_id)\n",
    "      print(\"Date of submission: \", r[\"date\"])\n",
    "      print(\"Time of submission: \", r[\"time\"])\n",
    "      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n",
    "      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
    "      return submission_id\n",
    "    else: submission_id\n",
    "    \n",
    "\n",
    "def getAdditional():\n",
    "  try:\n",
    "    if Additional: return Additional      \n",
    "    else: raise NameError('')\n",
    "  except NameError:\n",
    "    print (\"Please answer Additional Question\")\n",
    "    return None\n",
    "\n",
    "def getComplexity():\n",
    "  try:\n",
    "    return Complexity\n",
    "  except NameError:\n",
    "    print (\"Please answer Complexity Question\")\n",
    "    return None\n",
    "  \n",
    "def getConcepts():\n",
    "  try:\n",
    "    return Concepts\n",
    "  except NameError:\n",
    "    print (\"Please answer Concepts Question\")\n",
    "    return None\n",
    "\n",
    "def getAnswer():\n",
    "  try:\n",
    "    return Answer\n",
    "  except NameError:\n",
    "    print (\"Please answer Question\")\n",
    "    return None\n",
    "\n",
    "def getId():\n",
    "  try: \n",
    "    return Id if Id else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "def getPassword():\n",
    "  try:\n",
    "    return password if password else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "submission_id = None\n",
    "### Setup \n",
    "if getPassword() and getId():\n",
    "  submission_id = submit_notebook()\n",
    "  if submission_id:\n",
    "    setup()\n",
    "    from IPython.display import HTML\n",
    "    HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id))\n",
    "  \n",
    "else:\n",
    "  print (\"Please complete Id and Password cells before running setup\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OjItUTCN4Sff"
   },
   "source": [
    "#### Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDHz4w-rgxFO"
   },
   "outputs": [],
   "source": [
    "# Importing datasets package to load iris dataset \n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aktoIpOngxFT"
   },
   "outputs": [],
   "source": [
    "# Import PCA from sklearn.decomposition to project data from higher dimensions to lower dimensions\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLgMWawpgxFX"
   },
   "outputs": [],
   "source": [
    "# Import linear model to use the SGDClassifier further in the experiment\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_g0Qre1gxFb"
   },
   "outputs": [],
   "source": [
    "# Use load_iris() to get the data \n",
    "# It returns an object of the dataset\n",
    "data=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlWs3ncwgxFf"
   },
   "outputs": [],
   "source": [
    "# Get data from the dataset object 'data'\n",
    "dataArr=data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QvCYJZraQEe"
   },
   "outputs": [],
   "source": [
    "#### Let us check the type of the variable 'dataArr'\n",
    "type(dataArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2a7D0ZvgxFj"
   },
   "outputs": [],
   "source": [
    "#### Let us check the type of the dataset object 'data'\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ck1JPVsggxFp"
   },
   "outputs": [],
   "source": [
    "#### Let us get features present in the dataset from dataset object 'data'\n",
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8O6O_38gxFw"
   },
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVYaQX_G4__v"
   },
   "source": [
    "#### Split the data into train and test  sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpnQkIZEgxF2"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split from model_selection to split the data into train and test data\n",
    "trainData,testData,labelTrain,labelTest=model_selection.train_test_split(dataArr,data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJhgAzz95GM3"
   },
   "source": [
    "#### Look at the shape of the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aty3P1bRgxF5"
   },
   "outputs": [],
   "source": [
    "# shape will return number of rows and columns in a dataset\n",
    "trainData.shape,testData.shape, dataArr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC27YfQd5N84"
   },
   "source": [
    "#### Now, reduce the dimensions of data from 4D to 3D using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9n-VvrogxF-"
   },
   "outputs": [],
   "source": [
    "'''We use PCA technique from decomposition which takes as input\n",
    "number of components to keep in the lower dimension'''\n",
    "### We create an object of PCA class\n",
    "pca=PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdQPk_XGgxGB"
   },
   "outputs": [],
   "source": [
    "#### We are transforming and fitting the data to PCA by using principle components to project the data to lower dimensions \n",
    "dataReduced=pca.fit_transform(dataArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9Ah_9NsgxGF"
   },
   "outputs": [],
   "source": [
    "#### Let us check the type of the variable 'dataReduced'\n",
    "type(dataReduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odb-f-EQ5mq2"
   },
   "source": [
    "#### Plot the data after its dimensions are reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ums9sXL2gxGM"
   },
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RgQrQUndgxGR"
   },
   "outputs": [],
   "source": [
    "### Create a scatter plot with the reduced data across the 3 principle components\n",
    "fig= plt.figure(1,figsize=(8,6))\n",
    "axes=Axes3D(fig, elev=-150, azim=110)\n",
    "axes.scatter(dataReduced[:, 0], dataReduced[:, 1], dataReduced[:, 2], c=data.target,\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "axes.set_title(\"First three principal components\")\n",
    "axes.set_xlabel('1st principal component')\n",
    "axes.set_ylabel('2nd principal component')\n",
    "axes.set_zlabel('3rd principal component')\n",
    "axes.set_xticklabels([])\n",
    "axes.set_yticklabels([])\n",
    "axes.set_zticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "myKfXPmX5zEe"
   },
   "source": [
    "#### Now let us try to train various models using the data after its dimensions are reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRXoS0cvgxGX"
   },
   "outputs": [],
   "source": [
    "#### Use train_test_split from model_selection to split the reduced data into train and test data\n",
    "trainDataRed,testDataRed=model_selection.train_test_split(dataReduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VIVFnzHU6Aaj"
   },
   "source": [
    "#### Apply a Linear classifier on the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pU_52YXOD6hM"
   },
   "source": [
    "SGDClassifier calculates the gradient of the loss by iterating through each sample of the dataset and is updated with the learning rate ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1C4G1eogxGg"
   },
   "outputs": [],
   "source": [
    "'''We use SGDClassifier from linear_model which takes as input  \n",
    "the number of epochs the train data has to go through and\n",
    "and the stopping criterion for the algorithm i.e when loss reaches this threshhold\n",
    "''' \n",
    "# We create an object of Stochastic Gradient Descent Classifer class\n",
    "clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "# We are fitting the data to SGDClassifier \n",
    "clf.fit(trainData,labelTrain)\n",
    "# Returns the mean accuracy on the given test data and labels\n",
    "clf.score(testData,labelTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIMqQJcv6PyY"
   },
   "source": [
    "#### Apply Linear classifier on the reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LenWQyGrgxGw"
   },
   "outputs": [],
   "source": [
    "# We create an object of Stochastic Gradient Descent Classifer class\n",
    "clfPCA = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "# We are fitting the reduced data to SGDClassifier \n",
    "clfPCA.fit(trainDataRed,labelTrain)\n",
    "# Returns the mean accuracy on the given reduced test data and labels\n",
    "clfPCA.score(testDataRed,labelTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN9B-hyg6XBM"
   },
   "source": [
    "#### Apply KNN on the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYd2iHOLgxG5"
   },
   "outputs": [],
   "source": [
    "'''We use KNeighborsClassifier neighbors from  which takes as input  \n",
    "the number of epochs the train data has to go through and\n",
    "and the stopping criterion for the algorithm i.e when loss reaches this threshhold\n",
    "''' \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# We create an object of K Nearest Neighbors Classifer class\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3)\n",
    "# We are fitting the data to SGDClassifier\n",
    "clf2.fit(trainData,labelTrain)\n",
    "# Returns the mean accuracy on the given test data and labels\n",
    "clf2.score(testData,labelTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FuszvcNO6dLp"
   },
   "source": [
    "#### Apply KNN on reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDazcoqWgxG-"
   },
   "outputs": [],
   "source": [
    "# We create an object of K Nearest Neighbors Classifer class\n",
    "clf2PCA = KNeighborsClassifier(n_neighbors=3)\n",
    "# We are fitting the reduced data to SGDClassifier \n",
    "clf2PCA.fit(trainDataRed,labelTrain)\n",
    "# Returns the mean accuracy on the given reduced test data and labels\n",
    "clf2PCA.score(testDataRed,labelTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tS6JjQsi6iGl"
   },
   "source": [
    "#### Please answer the questions below to complete the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhAd5KxIgxHC"
   },
   "outputs": [],
   "source": [
    "#@title What is the type of covariance matrix of some data set in 4 dimensions a,b,c,d if all the data points a,b,c,d are independent? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
    "Answer = \"\" #@param [\"upper triangular form\", \"diagonal form\", \"lower triangular form\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TDDN4366m3C"
   },
   "outputs": [],
   "source": [
    "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
    "Complexity = \"\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FckCcEvr6vB_"
   },
   "outputs": [],
   "source": [
    "#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
    "Additional = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MA5mL37_6o7n"
   },
   "outputs": [],
   "source": [
    "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Concepts = \"\" #@param [\"Yes\", \"No\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "NK5Bk0r66q7D"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
    "try:\n",
    "  if submission_id:\n",
    "      return_id = submit_notebook()\n",
    "      if return_id : submission_id =return_id\n",
    "  else:\n",
    "      print(\"Please complete the setup first.\")\n",
    "except NameError:\n",
    "  print (\"Please complete the setup first.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "M1_004_PCA_Iris_C.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
